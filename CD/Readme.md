# Compiler Design Practicals

This repository contains practical implementations for Compiler Design course covering lexical analysis, tokenization, and symbol table management using both C and Python.

## 📁 Project Structure

```
CD/
├── C/                      # C implementations
│   ├── practical1_1.c     # String validation
│   ├── practical1_2.c     # Keyword counter
│   ├── Practical1_3.c     # Delimiter/punctuation identifier
│   ├── Practical1_4.c     # String/character literal recognizer
│   ├── ex.l               # Lex specification file
│   ├── lex.yy.c           # Generated lexer from Flex
│   ├── Practical2.c       # Symbol table implementation
│   ├── input.txt          # Test input for symbol table
│   └── *.exe              # Compiled executables
├── python/                 # Python implementations
│   ├── practical1_1.py    # Character validation
│   └── practical1_2.py    # Advanced tokenizer
├── Practicals.txt         # Assignment descriptions
└── README.md              # This file
```

## 🎯 Practical 1: Lexical Analysis Fundamentals

### Part A: String Validation

#### C Implementation ([`practical1_1.c`](C/practical1_1.c))
- **Purpose**: Validates if input string contains only alphanumeric characters, whitespaces, and allowed operators
- **Functions**:
  - `isAlpha()`, `isDigit()`, `isAlNum()` - Character type checking
  - `isSpace()`, `isOperator()` - Special character validation
  - `isValidString()` - Main validation logic
- **Usage**: Compile and run to check string validity

#### Python Implementation ([`practical1_1.py`](python/practical1_1.py))
- **Purpose**: Similar validation using custom character checking functions
- **Features**: Manual implementation of character type checking without using built-in methods
- **Usage**: `python practical1_1.py`

### Part B: Keyword Counter

#### [`practical1_2.c`](C/practical1_2.c)
- **Purpose**: Counts and identifies C keywords in source code
- **Features**:
  - Comprehensive C keyword list (34 keywords)
  - Word-by-word parsing with delimiter handling
  - Case-sensitive keyword matching
- **Algorithm**: Tokenizes input and matches against predefined keyword array
- **Usage**: Enter C source code to get keyword count

### Part C: Delimiter and Punctuation Identifier

#### [`Practical1_3.c`](C/Practical1_3.c)
- **Purpose**: Identifies and reports positions of delimiters and punctuation marks
- **Supported Delimiters**: `;`, `,`, `(`, `)`, `{`, `}`, `[`, `]`, `:`, `.`
- **Supported Punctuation**: `!`, `?`, `'`, `"`, `-`, `#`, `@`, `/`
- **Features**:
  - Multi-line input support
  - Position tracking
  - Real-time character analysis
- **Usage**: Enter code/text, terminate with `$` on new line

### Part D: String and Character Literal Recognition

#### [`Practical1_4.c`](C/Practical1_4.c)
- **Purpose**: Extracts and displays string literals (`"..."`) and character literals (`'...'`)
- **Features**:
  - Handles both single and double quotes
  - Extracts content between quotes
  - Simple quote-based parsing
- **Limitations**: Doesn't handle escaped quotes

### Part E: Lex Program for Token Recognition

#### [`ex.l`](C/ex.l) - Flex Specification
- **Purpose**: Defines lexical rules for tokenizing C-like code
- **Token Types**:
  - **Keywords**: `int`, `float`, `return`, `if`, `else`, `while`, `for`, `void`, `char`, `double`
  - **Identifiers**: Variable/function names
  - **Numbers**: Integers and floating-point
  - **Others**: Unrecognized characters
- **Generated Output**: [`lex.yy.c`](C/lex.yy.c) (auto-generated by Flex)

#### Advanced Python Tokenizer ([`practical1_2.py`](python/practical1_2.py))
- **Purpose**: Comprehensive tokenizer with statistics
- **Token Types**:
  - **KEYWORD**: Reserved words
  - **IDENTIFIER**: Variable/function names
  - **OPERATOR**: Arithmetic, logical, comparison operators
  - **DELIMITER**: Punctuation marks
  - **NUMBER**: Integer and floating-point numbers
  - **STRING**: String literals
  - **UNKNOWN**: Unrecognized characters

**Features**:
- Multi-character operator support (`==`, `!=`, `<=`, `>=`, `&&`, `||`)
- String literal handling with quote matching
- Comprehensive token statistics
- Detailed token classification

## 🗃️ Practical 2: Symbol Table Implementation

### [`Practical2.c`](C/Practical2.c) - Complete Symbol Table System

**Purpose**: Implements a full-featured symbol table for lexical analysis with error detection.

#### Core Features:

1. **Symbol Table Management**
   - Stores identifier name, data type, scope, and line number
   - Supports up to 100 identifiers
   - Handles multiple scopes (global, function-specific)

2. **Declaration Processing**
   - Extracts identifiers from declaration statements
   - Supports multiple declarations: `int x, y, z;`
   - Validates identifier format and uniqueness

3. **Usage Validation**
   - Checks if identifiers are declared before use
   - Scope-aware lookup (current scope → global scope)
   - Reports undeclared identifier usage

4. **Error Detection**
   - **Multiple declarations**: Same identifier in same scope
   - **Keyword misuse**: Using reserved words as identifiers
   - **Undeclared usage**: Using variables before declaration
   - **Invalid identifiers**: Malformed variable names

5. **Supported Data Types**
   - `int`, `float`, `double`, `char`, `void`
   - `long`, `short`, `unsigned`, `signed`

#### Test Input ([`input.txt`](C/input.txt))
Contains sample C code with various scenarios:
- Valid declarations
- Multiple declarations (error case)
- Keyword misuse (error case)
- Undeclared variable usage (error case)

#### Key Functions:
- `addIdentifier()` - Adds new symbols to table
- `findIdentifier()` - Searches for existing symbols
- `checkUndeclaredUsage()` - Validates identifier usage
- `processDeclaration()` - Parses declaration statements
- `displaySymbolTable()` - Shows formatted symbol table

## 🔧 How to Build and Run

### C Programs
```bash
# Navigate to C directory
cd C/

# Compile individual programs
gcc practical1_1.c -o practical1_1.exe
gcc practical1_2.c -o practical1_2.exe
gcc Practical1_3.c -o Practical1_3.exe
gcc Practical1_4.c -o Practical1_4.exe
gcc Practical2.c -o Practical2.exe

# For Lex program (requires Flex)
flex ex.l
gcc lex.yy.c -o lexer.exe

# Run programs
./practical1_1.exe
./practical1_2.exe
./Practical1_3.exe
./Practical1_4.exe
./Practical2.exe
./lexer.exe
```

### Python Programs
```bash
# Navigate to python directory
cd python/

# Run programs
python practical1_1.py
python practical1_2.py
```

## 📝 Sample Usage

### Tokenizer Example (Python)
```python
# Input
input_string = 'int x = 10; if (x > 5) print("Hello");'

# Output
('KEYWORD', 'int')
('IDENTIFIER', 'x')
('OPERATOR', '=')
('NUMBER', '10')
('DELIMITER', ';')
# ... and so on
```

### Symbol Table Example
```c
// Input (input.txt)
int x, y, z;
float average;
x = 10;
int x;  // Error: Multiple declaration

// Output
Added identifier: x (int) in scope global at line 1
Added identifier: y (int) in scope global at line 1  
Added identifier: z (int) in scope global at line 1
Added identifier: average (float) in scope global at line 2
Error: Multiple declaration of identifier 'x' in scope 'global' at line 4
```

## 🎓 Learning Objectives

1. **Lexical Analysis**: Understanding tokenization and pattern recognition
2. **Symbol Table Management**: Identifier storage and scope handling
3. **Error Detection**: Compile-time error identification
4. **Regular Expressions**: Pattern matching for tokens
5. **Data Structures**: Efficient symbol storage and retrieval
6. **Language Design**: Understanding compiler front-end components

## 🔍 Key Concepts Demonstrated

- **Finite State Automata**: Token recognition patterns
- **Hash Tables**: Efficient symbol lookup
- **Scope Resolution**: Variable visibility rules
- **Error Handling**: Graceful error reporting
- **Code Parsing**: Statement analysis and token extraction
- **Language Grammar**: Syntax rule implementation

## 📋 Assignment Details

Detailed assignment descriptions are available in [`Practicals.txt`](Practicals.txt), covering:
- **Practical 1**: Complete lexical analysis implementation
- **Practical 2**: Symbol table construction with error detection

This implementation serves as a foundation for understanding compiler design principles and lexical analysis techniques.